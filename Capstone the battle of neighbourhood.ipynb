{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on the Week1 and week2 of the Battle of Neighbourhood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My idea for the Capstone Project is to show that when driven by venue and location data from FourSquare, backed up with open source crime data, that it is possible to present the cautious and nervous traveller with a list of attractions to visit supplementd with a graphics showing the occurance of crime in the region of the venue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2:Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As noted below in the Further Development Section, it is possible to attempt quite complex and sophisticated scenarios when approaching this problem. However, given the size of the project and for simplicity only the following scenario will be addressed:\n",
    "\n",
    "   1.Query the FourSqaure website for the top sites in Chicago\n",
    "   2.Use the FourSquare API to get supplemental geographical data about the top sites\n",
    "   3.Use the FourSquare API to get top restaurent recommendations closest to each of the top site\n",
    "   4.Use open source Chicago Crime data to provide the user with additional crime data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section3:Methodology"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The first round of eploratory analysis was to examine the Top Venues and Restaurants Dataframes to determine if there was any correlation between variables.\n",
    "\n",
    "Unforfunately the only data attributes that could be analysed were the Latitude and Longitude attributes and their relationship to the venuse score. Top Venues was examined First."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Modelling The data\n",
    "    We choose the RandomForestClassifier to predict the crimes and it is the best model for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section4:Results & Prediction\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The idea for the Capstone Project is to show that when driven by venue and location data from FourSquare, backed up with open source crime data, that it is possible to present the cautious and nervous traveller with a list of attractions to visit supplementd with a graphics showing the occurance of crime in the region of the venue."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The travellers decides on a city location [in this case Chicago]\n",
    "The ForeSquare website is scrapped for the top venues in the city\n",
    "From this list of top venues the list is augmented with additional grographical data\n",
    "Using this additional geographical data the top nearby restaurents are selects\n",
    "The historical crime within a predetermined distance of all venues are obtained\n",
    "A map is presented to the to the traveller showing the selected venues and crime statistics of the area.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section5:Visulizations and Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Of the top ten venues 8 were identified as potentially dangerous to visit and 2 were deems safe. As there is no data to compare the predictions against the best way we will visualise the data again.\n",
    "\n",
    "We will look at the following 4 venues:\n",
    "\n",
    "Millennium Park 41.882699 -87.623644\n",
    "The Chicago Theatre 41.885578 -87.627286\n",
    "Grant Park 41.873407 -87.620747\n",
    "Nature Boardwalk 41.918102 -87.633283\n",
    "The Distance Dataframe is recreated again but this time all crimes are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section6:Conclusions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Although all of the goals of this project were met there is definitely room for further improvement and development as noted below. However, the goals of the project were met and, with some more work, could easily be devleoped into a fully phledged application that could support the cautious traveller in an unknown location.\n",
    "\n",
    "Of the contributing data the Chicago Crime data is the one where more data would be good to have. Also not every city in the world makes this data freely available so that is a drawback.\n",
    "\n",
    "FourSquare proved to be a good source of data but frustrating at times. Despite having a Developer account I regularly exceeded my hourly limit locking me out for the day. This is why Pickle was used to store the captured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "font = {'size'   : 12}\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from folium import plugins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id='YURZRKYU4QKYI0RWD23WDREQE2VQF1QTU2ZZI052Y1NDD00C'\n",
    "client_secret='UXD0B1DAQSS5IGCSA2YCOZX4BHBFIZXXLTNZ5MEIOOJ0OANL'\n",
    "limit=50\n",
    "version='20180604'\n",
    "intent='browse'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "def cross_validate(model, n_splits = 10):\n",
    "    \n",
    "    k_fold = KFold(n_splits = n_splits)\n",
    "    scores = [model.fit(X[train], y[train]).score(X[test], y[test]) for train, test in k_fold.split(X)]\n",
    "    \n",
    "    scores = np.percentile(scores, [40, 50, 60])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the chicago crime data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the non required columns from the data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Removed Cols:\n",
    "    IUCR\n",
    "    ARREST\n",
    "    DOMESTIC\n",
    "    BEAT\n",
    "    WARD\n",
    "    FBI CD\n",
    "    X COORDINATE\n",
    "    Y COORDINATE\n",
    "    LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('crimes.csv',usecols=['CASE#',\n",
    "                      'DATE  OF OCCURRENCE',\n",
    "                      'BLOCK', \n",
    "                      ' PRIMARY DESCRIPTION',\n",
    "                      'WARD',\n",
    "                      'LATITUDE',\n",
    "                      'LONGITUDE'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('\\s{2,}', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('#', '')\n",
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_of_occurrence'] =  pd.to_datetime(df['date_of_occurrence'], format='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['date_of_occurrence'].dt.hour\n",
    "df['day_name'] = df['date_of_occurrence'].dt.day_name()\n",
    "df['day'] = df['date_of_occurrence'].dt.dayofweek + 1\n",
    "df['month_name'] = df['date_of_occurrence'].dt.month_name()\n",
    "df['month'] = df['date_of_occurrence'].dt.month\n",
    "df['year'] = df['date_of_occurrence'].dt.year\n",
    "df['year_month'] = df['date_of_occurrence'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zip']=df.block.str.split(' ').str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['street']=df.block.str.split(' ').str[1:].apply(', '.join)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization of crime Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Number of crimes per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('year_month').count().plot(y='case',kind='bar',figsize=(10,6),width=0.85,colormap='tab20')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Cases')\n",
    "plt.title('Count of cases per month',loc='left',fontsize=18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Crimes per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('day').count().plot(y='case',kind='bar',width=0.85,figsize=(10,6),colormap='tab20')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Number of Cases')\n",
    "plt.title('Count of cases per Day',loc='left',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of cases per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('hour').count().plot(y='case',kind='bar',width=0.85,figsize=(10,6),colormap='tab20')\n",
    "\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Cases')\n",
    "plt.title('Count of cases per Hour',loc='left',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.primary_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.primary_description.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['primary_description','case']].groupby('primary_description',as_index=False).count().sort_values('case',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_crimes = df[['primary_description', 'case']].groupby(\n",
    "    ['primary_description']).count().sort_values('case', ascending=False)[:10].axes[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_three_crimes = df[['primary_description', 'case']].groupby(\n",
    "    ['primary_description']).count().sort_values('case', ascending=False)[:3].axes[0].tolist()\n",
    "top_two_crimes = df[['primary_description', 'case']].groupby(\n",
    "    ['primary_description']).count().sort_values('case', ascending=False)[:2].axes[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_crimes = df[df['primary_description'].isin(top_crimes)].copy()\n",
    "\n",
    "df_top3_crimes = df[df['primary_description'].isin(top_three_crimes)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top3_crimes[['case', 'primary_description', 'year_month']].pivot_table(\n",
    "    index='year_month', \n",
    "    columns='primary_description',  \n",
    "    aggfunc='count').plot(kind='area',\n",
    "                          stacked=True,\n",
    "                          figsize=(15, 6),\n",
    "                               fontsize=12,\n",
    "                               colormap='tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top3_crimes[['case', 'primary_description', 'hour']].pivot_table(\n",
    "    index='hour', \n",
    "    columns='primary_description', \n",
    "    fill_value=0, \n",
    "    aggfunc='count').plot(kind='area',\n",
    "                          stacked=True,\n",
    "                          figsize=(15, 6),\n",
    "                               fontsize=12,\n",
    "                               colormap='tab20')\n",
    "\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Count of Cases per Hour')\n",
    "plt.title('Count of Cases Per Hour]', loc='left', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Crimes On Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colours for top ten crimes\n",
    "colors = [\n",
    "    'red',\n",
    "    'blue',\n",
    "    'gray',\n",
    "    'orange',\n",
    "    'beige',\n",
    "    'green',\n",
    "    'purple',\n",
    "    'pink',\n",
    "    'cadetblue',\n",
    "    'black'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_colours = dict(zip(top_crimes, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_crimes['colour'] = df_top_crimes.primary_description.map(dict_colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_crimes_may = df_top_crimes[df_top_crimes.month_name == 'May']\n",
    "df_top_crimes_may.to_pickle('crimes_may.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_latitude = 41.85  \n",
    "chicago_longitude = -87.75\n",
    "\n",
    "chicago_map = folium.Map(location=[chicago_latitude, chicago_longitude], zoom_start=11)\n",
    "\n",
    "chicago_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "incidents = folium.map.FeatureGroup()\n",
    "\n",
    "# loop through the 100 crimes and add each to the incidents feature group\n",
    "for lat, lng, col in zip(df_top_crimes_may.latitude, \n",
    "                         df_top_crimes_may.longitude, \n",
    "                         df_top_crimes_may.colour):\n",
    "    incidents.add_child(\n",
    "        folium.CircleMarker(\n",
    "            [lat, lng],\n",
    "            radius=1, # define how big you want the circle markers to be\n",
    "            color=col,\n",
    "            fill=True,\n",
    "            fill_color=col,\n",
    "            fill_opacity=0.6\n",
    "        )\n",
    "    )\n",
    "\n",
    "# add incidents to map\n",
    "chicago_map.add_child(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MarkerCluster()\n",
    "\n",
    "# Define the world map centered around Chicago with a higher zoom level\n",
    "chicago_cluster = folium.Map(location=[chicago_latitude, chicago_longitude], zoom_start=11)\n",
    "\n",
    "# display world map\n",
    "chicago_cluster\n",
    "\n",
    "#creating a Marker for each point in df_sample. Each point will get a popup with their zip\n",
    "for row in df_top_crimes_may.itertuples():\n",
    "    mc.add_child(folium.Marker(\n",
    "        location=[row.latitude,  row.longitude],\n",
    "                 popup=row.primary_description))\n",
    "\n",
    "chicago_cluster.add_child(mc)\n",
    "chicago_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "chicago_heatmat = folium.Map(location=[chicago_latitude, chicago_longitude], zoom_start=11) \n",
    "\n",
    "# List comprehension to make out list of lists\n",
    "heat_data = [[row['latitude'], \n",
    "              row['longitude']] for index, row in df_top_crimes_may.iterrows()]\n",
    "\n",
    "# Plot it on the map\n",
    "HeatMap(heat_data,\n",
    "        min_opacity=0.5,\n",
    "        max_zoom=18, \n",
    "        max_val=1.0, \n",
    "        radius=15,\n",
    "        blur=20,\n",
    "        gradient=None,\n",
    "        overlay=True).add_to(chicago_heatmat)\n",
    "\n",
    "# Display the map\n",
    "chicago_heatmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=df_top_crimes[['latitude','longitude']]\n",
    "df_features=df_features.join(pd.get_dummies(df_top_crimes.hour,prefix='hour'))\n",
    "df_features=df_features.join(pd.get_dummies(df_top_crimes.day_name))\n",
    "df_features=df_features.join(pd.get_dummies(df_top_crimes.month_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['ward'] = df_top_crimes[['ward']]\n",
    "df_features['crimes'] = df_top_crimes[['primary_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_3 = df_features[df_features['crimes'].isin(top_three_crimes)].copy()\n",
    "df_features_2 = df_features[df_features['crimes'].isin(top_two_crimes)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10 = df_features.copy()\n",
    "y_10 = X_10.crimes.values\n",
    "\n",
    "X_10.drop('crimes', axis=1, inplace=True)\n",
    "X_10 = preprocessing.StandardScaler().fit(X_10).transform(X_10)\n",
    "\n",
    "\n",
    "X_3 = df_features_3.copy()\n",
    "y_3 = X_3.crimes.values\n",
    "\n",
    "X_3.drop('crimes', axis=1, inplace=True)\n",
    "X_3 = preprocessing.StandardScaler().fit(X_3).transform(X_3)\n",
    "\n",
    "X_2 = df_features_2.copy()\n",
    "y_2 = X_2.crimes.values\n",
    "\n",
    "X_2.drop('crimes', axis=1, inplace=True)\n",
    "X_2 = preprocessing.StandardScaler().fit(X_2).transform(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator:  12   2020-05-01 17:02:33.516826\n",
      "Estimator:  13   2020-05-01 17:04:47.655924\n",
      "Estimator:  14   2020-05-01 17:07:09.145047\n"
     ]
    }
   ],
   "source": [
    "X = X_10\n",
    "y = y_10\n",
    "from datetime import datetime\n",
    "est = range(12, 17)\n",
    "scores = np.zeros((len(est), 3))\n",
    "for idx, a in enumerate(est):\n",
    "    print('Estimator: ', a, ' ', str(datetime.now()))\n",
    "    model = RandomForestClassifier(n_estimators = a, max_features = 'sqrt')\n",
    "    scores[idx, : ] = cross_validate(model, n_splits = 10)\n",
    "\n",
    "plt.plot(est, scores[ : , 1], 'b')\n",
    "plt.fill_between(est, scores[ : , 0], scores[:, 2], alpha = 0.1)\n",
    "plt.legend(('Median', '(40, 60) percentile'))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "page = requests.get(\"https://foursquare.com/explore?mode=url&near=Chicago%2C%20IL%2C%20United%20States&nearGeoId=72057594042815334&q=Top%20Picks\")\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "top_venues = soup.find_all('div', class_='venueDetails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_columns = ['id', \n",
    "                 'score', \n",
    "                 'category', \n",
    "                 'name', \n",
    "                 'address',\n",
    "                 'postalcode',\n",
    "                 'city',\n",
    "                 'href', \n",
    "                 'latitude', \n",
    "                 'longitude']\n",
    "\n",
    "df_top_venues = pd.DataFrame(columns=venue_columns)\n",
    "\n",
    "for venue in top_venues:\n",
    "    venue_name = venue.find(target=\"_blank\").get_text()\n",
    "    venue_score = venue.find(class_=\"venueScore positive\").get_text()\n",
    "    venue_cat = venue.find(class_=\"categoryName\").get_text()\n",
    "    venue_href = venue.find(class_=\"venueName\").h2.a['href']\n",
    "    venue_id = venue_href.split('/')[-1]\n",
    "\n",
    "    if 'promotedTipId' in venue_id: \n",
    "        continue\n",
    "        \n",
    "    # Get the properly formatted address and the latitude and longitude\n",
    "    url = 'https://api.foursquare.com/v2/venues/{}?client_id={}&client_secret={}&v={}'.format(\n",
    "        venue_id, \n",
    "        client_id,\n",
    "        client_secret,\n",
    "        version)\n",
    "    \n",
    "    result = requests.get(url).json()\n",
    "    \n",
    "    print(result)\n",
    "    venue_address = result['response']['venue']['location']['address']\n",
    "    venue_postalcode = result['response']['venue']['location']['postalCode']\n",
    "    venue_city = result['response']['venue']['location']['city']\n",
    "    venue_latitude = result['response']['venue']['location']['lat']\n",
    "    venue_longitude = result['response']['venue']['location']['lng']\n",
    "    \n",
    "    df_top_venues = df_top_venues.append({'id': venue_id,\n",
    "                                          'score': venue_score,\n",
    "                                          'category': venue_cat,\n",
    "                                          'name': venue_name,\n",
    "                                          'address': venue_address,\n",
    "                                          'postalcode': venue_postalcode,\n",
    "                                          'city': venue_city,\n",
    "                                          'href': venue_href,\n",
    "                                          'latitude': venue_latitude,\n",
    "                                          'longitude': venue_longitude}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_venues=pd.read_pickle('top_venues.pkl')\n",
    "df_top_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_venues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_venues['score'] = pd.to_numeric(df_top_venues['score'], errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_columns = ['id',\n",
    "                       'score', \n",
    "                       'category', \n",
    "                       'categoryID', \n",
    "                       'name', \n",
    "                       'address',\n",
    "                       'postalcode',\n",
    "                       'city',\n",
    "                       'latitude',\n",
    "                       'longitude', \n",
    "                       'venue_name', \n",
    "                       'venue_latitude',\n",
    "                       'venue_longitude']\n",
    "\n",
    "df_restaurant = pd.DataFrame(columns=restaurants_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_venue_lats = df_top_venues['latitude'].values\n",
    "top_venue_lngs = df_top_venues['longitude'].values\n",
    "\n",
    "top_venue_names = df_top_venues['name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ven_name, ven_lat, ven_long in zip(top_venue_names, top_venue_lats, top_venue_lngs):\n",
    "    # print(ven_id, ven_name)\n",
    "    \n",
    "    # Configure additional Search parameters\n",
    "    categoryId = '4d4b7105d754a06374d81259'\n",
    "    radius = 500\n",
    "    limit = 15\n",
    "    \n",
    "    url = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&categoryId={}&radius={}&limit={}'.format(\n",
    "        client_id,\n",
    "        client_secret,\n",
    "        ven_lat,\n",
    "        ven_long,\n",
    "        version,\n",
    "        categoryId,\n",
    "        radius,\n",
    "        limit)\n",
    "    \n",
    "    results = requests.get(url).json()\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurant = pd.read_pickle('restaurants.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_restaurant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurant.venue_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurant.groupby('category')['name'].count().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_restaurants= df_restaurant[['id', 'score','address','venue_latitude','venue_longitude','postalcode']].groupby(\n",
    "    ['id','address','venue_latitude','venue_longitude','postalcode']).count().sort_values('score', ascending=False)[:10].axes[0].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
